<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera UI</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
            font-family: Arial, sans-serif;
            text-align: center;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #video-container {
            display: none; /* Hide video container */
        }
        #video {
            display: none; /* Hide video element */
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
        }
        button:hover {
            background-color: #0056b3;
        }
        #emotion-result {
            margin-top: 20px;
            font-size: 20px;
            color: #333;
        }
        #processed-frame {
            display: none; /* Hide processed frame initially */
            margin-top: 20px;
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Facial Emotion to Audio Conversion</h1>
        <div id="video-container">
            <video autoplay="true" id="videoelement"></video>
        </div>
        <button onclick="predictEmotion()">Predict Emotion</button>
        <div id="emotion-result"></div>
        <img id="processed-frame" />
    </div>

    <script>
        let video = document.querySelector("#videoelement");
        let canvas = document.createElement("canvas");
        let context = canvas.getContext("2d");

        if (navigator.mediaDevices.getUserMedia) {
            navigator.mediaDevices.getUserMedia({ video: true }).then(function (stream) {
                video.srcObject = stream;
                video.onloadedmetadata = function () {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    startCapturing();
                };
            }).catch(function (error) {
                console.log("Something went wrong", error);
            });
        } else {
            console.log("getUserMedia not supported");
        }

        function startCapturing() {
            setInterval(() => {
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                canvas.toBlob(blob => {
                    let formData = new FormData();
                    formData.append('video_frame', blob);

                    fetch('/process_frame', {
                        method: 'POST',
                        body: formData
                    }).then(response => response.blob()) // Handle response as blob
                      .then(blob => {
                          let img = document.getElementById('processed-frame');
                          img.src = URL.createObjectURL(blob); // Create URL for image blob
                          img.style.display = 'block'; // Show the image
                      })
                      .catch(error => console.error('Error:', error));
                }, 'image/jpeg');
            }, 100); // Adjust the interval as needed
        }

        function predictEmotion() {
            fetch('/predict_emotion', {
                method: 'GET' // Ensure that the request method is POST
            })
            .then(response => response.json())
            .then(data => {
                document.getElementById('emotion-result').innerText = `Emotion: ${data.emotion}`;
            })
            .catch(error => console.error('Error:', error));
        }
    </script>
</body>
</html>
